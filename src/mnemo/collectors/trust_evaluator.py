"""ì™¸ë¶€ ì§€ì‹ ì‹ ë¢°ë„ í‰ê°€ + í¬ë¡œìŠ¤ì²´í¬ ì‹œìŠ¤í…œ

ì‹ ë¢°ë„ í‰ê°€ ê¸°ì¤€:
1. ì†ŒìŠ¤ ì‹ ë¢°ë„ (Source Trust) â€” ì¶œì²˜ì˜ ê¶Œìœ„/ì‹ ë¢°ì„±
2. êµì°¨ ê²€ì¦ (Cross-check) â€” ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ê°™ì€ ì •ë³´ í™•ì¸
3. ë‚´ë¶€ ì¼ê´€ì„± (Internal Consistency) â€” ê¸°ì¡´ ì§€ì‹ê·¸ë˜í”„ì™€ ëª¨ìˆœ ì—¬ë¶€
4. ì‹œì˜ì„± (Freshness) â€” ì •ë³´ì˜ ìµœì‹ ì„±
5. êµ¬ì²´ì„± (Specificity) â€” ì£¼ì¥ì˜ êµ¬ì²´ì„±/ê²€ì¦ê°€ëŠ¥ì„±

ì‹ ë¢°ë„ ë“±ê¸‰:
  A (0.8~1.0): ë†’ì€ ì‹ ë¢° â€” ê³µì‹ ë¬¸ì„œ, í•™ìˆ  ë…¼ë¬¸, ë³µìˆ˜ ì†ŒìŠ¤ í™•ì¸
  B (0.6~0.8): ë³´í†µ ì‹ ë¢° â€” ì „ë¬¸ ë¸”ë¡œê·¸, ë‹¨ì¼ ì‹ ë¢° ì†ŒìŠ¤
  C (0.4~0.6): ë‚®ì€ ì‹ ë¢° â€” ê°œì¸ ì˜ê²¬, ë¯¸í™•ì¸, ì†Œì…œë¯¸ë””ì–´
  D (0.0~0.4): ë¯¸ì‹ ë¢° â€” ëª¨ìˆœ ë°œê²¬, ì¶œì²˜ ë¶ˆëª…, ê´‘ê³ ì„±
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from datetime import datetime, timedelta

from .web_collector import CollectedKnowledge, SearchResult


# ì†ŒìŠ¤ ë„ë©”ì¸ ì‹ ë¢°ë„ ì‚¬ì „
DOMAIN_TRUST = {
    # ë†’ì€ ì‹ ë¢° (0.9+)
    "arxiv.org": 0.95,
    "github.com": 0.85,
    "docs.python.org": 0.95,
    "pytorch.org": 0.90,
    "huggingface.co": 0.85,
    "openai.com": 0.90,
    "anthropic.com": 0.90,
    "google.ai": 0.90,
    "microsoft.com": 0.85,
    "ieee.org": 0.95,
    "acm.org": 0.95,
    "nature.com": 0.95,
    "sciencedirect.com": 0.90,
    # ë³´í†µ ì‹ ë¢° (0.6~0.8)
    "medium.com": 0.60,
    "dev.to": 0.65,
    "stackoverflow.com": 0.75,
    "reddit.com": 0.50,
    "youtube.com": 0.55,
    "towardsdatascience.com": 0.70,
    "techcrunch.com": 0.75,
    "theverge.com": 0.70,
    "wired.com": 0.75,
    # ë‚®ì€ ì‹ ë¢° (ê¸°ë³¸ê°’)
    "_default": 0.45,
}

# ì‹ ë¢° í‚¤ì›Œë“œ (ë‚´ìš©ì— í¬í•¨ ì‹œ ê°€ì‚°/ê°ì‚°)
TRUST_BOOST_KEYWORDS = [
    "peer-reviewed", "published", "benchmark", "experiment",
    "official", "documentation", "specification", "RFC",
    "ì—°êµ¬", "ë…¼ë¬¸", "ì‹¤í—˜", "ë²¤ì¹˜ë§ˆí¬", "ê³µì‹",
]
TRUST_PENALTY_KEYWORDS = [
    "sponsored", "advertisement", "affiliate", "opinion",
    "rumor", "unconfirmed", "alleged", "clickbait",
    "ê´‘ê³ ", "í˜‘ì°¬", "ì¶”ì¸¡", "ë£¨ë¨¸", "ë¯¸í™•ì¸",
]


@dataclass
class TrustScore:
    """ì‹ ë¢°ë„ í‰ê°€ ê²°ê³¼"""
    overall: float = 0.0
    source_trust: float = 0.0
    cross_check: float = 0.0
    consistency: float = 0.0
    freshness: float = 0.0
    specificity: float = 0.0
    grade: str = "D"
    reasons: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)

    @property
    def grade_emoji(self) -> str:
        return {"A": "ğŸŸ¢", "B": "ğŸ”µ", "C": "ğŸŸ¡", "D": "ğŸ”´"}.get(self.grade, "âšª")


def _extract_domain(url: str) -> str:
    """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
    match = re.search(r"https?://(?:www\.)?([^/]+)", url)
    return match.group(1) if match else ""


def _score_source_trust(results: list[SearchResult]) -> tuple[float, list[str]]:
    """ì†ŒìŠ¤ ì‹ ë¢°ë„ í‰ê°€"""
    if not results:
        return 0.0, ["ê²°ê³¼ ì—†ìŒ"]

    scores = []
    reasons = []

    for r in results:
        domain = _extract_domain(r.url)
        # ë„ë©”ì¸ ë§¤ì¹­ (ë¶€ë¶„ ë§¤ì¹­)
        trust = DOMAIN_TRUST.get("_default", 0.45)
        for known_domain, known_trust in DOMAIN_TRUST.items():
            if known_domain in domain:
                trust = known_trust
                break

        # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤/íŒ¨ë„í‹°
        content = (r.title + " " + r.snippet).lower()
        for kw in TRUST_BOOST_KEYWORDS:
            if kw.lower() in content:
                trust = min(trust + 0.05, 1.0)
        for kw in TRUST_PENALTY_KEYWORDS:
            if kw.lower() in content:
                trust = max(trust - 0.1, 0.1)

        scores.append(trust)
        if trust >= 0.8:
            reasons.append(f"ì‹ ë¢° ì†ŒìŠ¤: {domain} ({trust:.2f})")
        elif trust < 0.5:
            reasons.append(f"ë‚®ì€ ì‹ ë¢°: {domain} ({trust:.2f})")

    return sum(scores) / len(scores), reasons


def _score_cross_check(results: list[SearchResult]) -> tuple[float, list[str]]:
    """êµì°¨ ê²€ì¦ â€” ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ìœ ì‚¬í•œ ì •ë³´ í™•ì¸"""
    if len(results) < 2:
        return 0.3, ["ë‹¨ì¼ ì†ŒìŠ¤ â€” êµì°¨ ê²€ì¦ ë¶ˆê°€"]

    # ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ ìˆ˜
    domains = set(_extract_domain(r.url) for r in results)
    domain_diversity = min(len(domains) / 3.0, 1.0)  # 3ê°œ ì´ìƒì´ë©´ ë§Œì 

    # ë‚´ìš© ìœ ì‚¬ë„ (í‚¤ì›Œë“œ ê²¹ì¹¨)
    all_words = []
    for r in results:
        words = set(re.findall(r'\w{3,}', (r.title + " " + r.snippet).lower()))
        all_words.append(words)

    overlap_scores = []
    for i in range(len(all_words)):
        for j in range(i + 1, len(all_words)):
            if all_words[i] and all_words[j]:
                overlap = len(all_words[i] & all_words[j]) / min(len(all_words[i]), len(all_words[j]))
                overlap_scores.append(overlap)

    content_agreement = sum(overlap_scores) / len(overlap_scores) if overlap_scores else 0.0

    score = 0.5 * domain_diversity + 0.5 * content_agreement
    reasons = []
    reasons.append(f"{len(domains)}ê°œ ì†ŒìŠ¤ í™•ì¸ (ë‹¤ì–‘ì„±: {domain_diversity:.2f})")
    if content_agreement > 0.3:
        reasons.append(f"ì†ŒìŠ¤ ê°„ ë‚´ìš© ì¼ì¹˜ë„: {content_agreement:.2f}")
    else:
        reasons.append(f"ì†ŒìŠ¤ ê°„ ë‚´ìš© ë¶ˆì¼ì¹˜: {content_agreement:.2f}")

    return score, reasons


def _score_freshness(results: list[SearchResult]) -> tuple[float, list[str]]:
    """ì‹œì˜ì„± í‰ê°€"""
    now = datetime.now()
    reasons = []

    # ë‚ ì§œ íŒŒì‹± ì‹œë„
    dates_found = 0
    recent_count = 0

    for r in results:
        date_str = r.date
        if not date_str:
            continue

        # "2 days ago", "1 week ago" ë“±
        if "day" in date_str.lower():
            dates_found += 1
            recent_count += 1
        elif "week" in date_str.lower():
            dates_found += 1
            recent_count += 1
        elif "month" in date_str.lower():
            dates_found += 1
        elif re.match(r"\d{4}-\d{2}-\d{2}", date_str):
            dates_found += 1
            try:
                d = datetime.strptime(date_str[:10], "%Y-%m-%d")
                if (now - d).days < 90:
                    recent_count += 1
            except ValueError:
                pass

    if dates_found == 0:
        return 0.5, ["ë‚ ì§œ ì •ë³´ ì—†ìŒ"]

    freshness = recent_count / dates_found
    if freshness > 0.5:
        reasons.append(f"ìµœê·¼ ì •ë³´ ë¹„ìœ¨: {recent_count}/{dates_found}")
    else:
        reasons.append(f"ì˜¤ë˜ëœ ì •ë³´ ë‹¤ìˆ˜: {dates_found - recent_count}/{dates_found}")

    return freshness, reasons


def _score_specificity(results: list[SearchResult]) -> tuple[float, list[str]]:
    """êµ¬ì²´ì„± í‰ê°€ â€” ìˆ˜ì¹˜, ë°ì´í„°, êµ¬ì²´ì  ì£¼ì¥ í¬í•¨ ì—¬ë¶€"""
    specificity_indicators = 0
    total_checked = 0
    reasons = []

    for r in results:
        content = r.title + " " + r.snippet
        total_checked += 1

        # ìˆ˜ì¹˜ í¬í•¨
        if re.search(r'\d+\.?\d*\s*(%|percent|ë°°|times|x)', content, re.IGNORECASE):
            specificity_indicators += 1
        # ë‚ ì§œ/ë²„ì „ í¬í•¨
        if re.search(r'(v?\d+\.\d+|20\d{2})', content):
            specificity_indicators += 1
        # ë¹„êµ/ë²¤ì¹˜ë§ˆí¬
        if re.search(r'(vs|compared|benchmark|outperform|ëŒ€ë¹„|ë¹„êµ)', content, re.IGNORECASE):
            specificity_indicators += 1

    if total_checked == 0:
        return 0.5, ["í‰ê°€ ë¶ˆê°€"]

    score = min(specificity_indicators / (total_checked * 2), 1.0)
    if score > 0.5:
        reasons.append(f"êµ¬ì²´ì  ë°ì´í„° í¬í•¨ ({specificity_indicators}ê°œ ì§€í‘œ)")
    else:
        reasons.append("êµ¬ì²´ì  ìˆ˜ì¹˜/ë°ì´í„° ë¶€ì¡±")

    return score, reasons


def evaluate_trust(
    knowledge: CollectedKnowledge,
    existing_notes: list[str] | None = None,
) -> TrustScore:
    """ì™¸ë¶€ ì§€ì‹ì˜ ì¢…í•© ì‹ ë¢°ë„ í‰ê°€

    Args:
        knowledge: ìˆ˜ì§‘ëœ ì™¸ë¶€ ì§€ì‹
        existing_notes: ê¸°ì¡´ ë³¼íŠ¸ì˜ ë…¸íŠ¸ ì´ë¦„ ëª©ë¡ (ì¼ê´€ì„± ê²€ì‚¬ìš©)

    Returns:
        TrustScore
    """
    ts = TrustScore()

    # 1. ì†ŒìŠ¤ ì‹ ë¢°ë„ (30%)
    ts.source_trust, src_reasons = _score_source_trust(knowledge.results)
    ts.reasons.extend(src_reasons)

    # 2. êµì°¨ ê²€ì¦ (25%)
    ts.cross_check, xc_reasons = _score_cross_check(knowledge.results)
    ts.reasons.extend(xc_reasons)

    # 3. ë‚´ë¶€ ì¼ê´€ì„± (15%) â€” ê¸°ì¡´ ì§€ì‹ê³¼ ëª¨ìˆœ ì²´í¬
    if existing_notes:
        # í† í”½ ê´€ë ¨ ê¸°ì¡´ ë…¸íŠ¸ ì¡´ì¬ ì—¬ë¶€
        topic_words = set(re.findall(r'\w{3,}', knowledge.topic.lower()))
        related = sum(1 for n in existing_notes if topic_words & set(re.findall(r'\w{3,}', n.lower())))
        ts.consistency = min(related / 5.0, 1.0) if related > 0 else 0.5
        if related > 0:
            ts.reasons.append(f"ê¸°ì¡´ ê´€ë ¨ ë…¸íŠ¸ {related}ê°œ (ì¼ê´€ì„± ê²€ì¦ ê°€ëŠ¥)")
        else:
            ts.reasons.append("ê¸°ì¡´ ê´€ë ¨ ì§€ì‹ ì—†ìŒ â€” ì‹ ê·œ í† í”½")
    else:
        ts.consistency = 0.5

    # 4. ì‹œì˜ì„± (15%)
    ts.freshness, fresh_reasons = _score_freshness(knowledge.results)
    ts.reasons.extend(fresh_reasons)

    # 5. êµ¬ì²´ì„± (15%)
    ts.specificity, spec_reasons = _score_specificity(knowledge.results)
    ts.reasons.extend(spec_reasons)

    # ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
    ts.overall = (
        0.30 * ts.source_trust
        + 0.25 * ts.cross_check
        + 0.15 * ts.consistency
        + 0.15 * ts.freshness
        + 0.15 * ts.specificity
    )

    # ë“±ê¸‰
    if ts.overall >= 0.8:
        ts.grade = "A"
    elif ts.overall >= 0.6:
        ts.grade = "B"
    elif ts.overall >= 0.4:
        ts.grade = "C"
    else:
        ts.grade = "D"

    # ê²½ê³ 
    if ts.source_trust < 0.5:
        ts.warnings.append("âš ï¸ ì†ŒìŠ¤ ì‹ ë¢°ë„ ë‚®ìŒ â€” ì¶”ê°€ ê²€ì¦ ê¶Œì¥")
    if ts.cross_check < 0.3:
        ts.warnings.append("âš ï¸ êµì°¨ ê²€ì¦ ë¶€ì¡± â€” ë‹¨ì¼ ì†ŒìŠ¤ ì˜ì¡´")
    if ts.overall < 0.4:
        ts.warnings.append("ğŸ”´ ì‹ ë¢°ë„ Dë“±ê¸‰ â€” ì§€ì‹ê·¸ë˜í”„ í¸ì… ë³´ë¥˜ ê¶Œì¥")

    return ts


def trust_to_frontmatter(ts: TrustScore) -> dict:
    """ì‹ ë¢°ë„ í‰ê°€ ê²°ê³¼ë¥¼ frontmatter í•„ë“œë¡œ ë³€í™˜"""
    return {
        "trust_grade": ts.grade,
        "trust_score": round(ts.overall, 2),
        "trust_source": round(ts.source_trust, 2),
        "trust_crosscheck": round(ts.cross_check, 2),
        "trust_freshness": round(ts.freshness, 2),
        "trust_specificity": round(ts.specificity, 2),
    }


def trust_to_markdown(ts: TrustScore) -> str:
    """ì‹ ë¢°ë„ í‰ê°€ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ìœ¼ë¡œ"""
    lines = [
        f"## ì‹ ë¢°ë„ í‰ê°€ {ts.grade_emoji} {ts.grade} ({ts.overall:.2f})",
        "",
        "| í•­ëª© | ì ìˆ˜ |",
        "|------|------|",
        f"| ì†ŒìŠ¤ ì‹ ë¢°ë„ | {ts.source_trust:.2f} |",
        f"| êµì°¨ ê²€ì¦ | {ts.cross_check:.2f} |",
        f"| ë‚´ë¶€ ì¼ê´€ì„± | {ts.consistency:.2f} |",
        f"| ì‹œì˜ì„± | {ts.freshness:.2f} |",
        f"| êµ¬ì²´ì„± | {ts.specificity:.2f} |",
        f"| **ì¢…í•©** | **{ts.overall:.2f}** |",
        "",
    ]

    if ts.reasons:
        lines.append("**ê·¼ê±°:**")
        for r in ts.reasons:
            lines.append(f"- {r}")
        lines.append("")

    if ts.warnings:
        lines.append("**ê²½ê³ :**")
        for w in ts.warnings:
            lines.append(f"- {w}")

    return "\n".join(lines)
